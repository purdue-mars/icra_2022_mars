diff --git a/CMakeLists.txt b/CMakeLists.txt
index a1b7bd9..4333e86 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -56,5 +56,6 @@ catkin_install_python(PROGRAMS scripts/call_icp.py scripts/gelsight_proc.py scri
 
 pybind11_add_module(find_marker MODULE src/tracking_class.cpp)
 install(TARGETS find_marker
-  LIBRARY DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}
-)
\ No newline at end of file
+  LIBRARY DESTINATION ${PYTHON_INSTALL_DIR}
+  RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}
+)
diff --git a/config/gelsight_proc.yml b/config/gelsight_proc.yml
index 24711f9..743c2ab 100644
--- a/config/gelsight_proc.yml
+++ b/config/gelsight_proc.yml
@@ -1,5 +1,17 @@
 cam_url: "http://192.168.0.170:8080/?action=stream"
 
+image_size:
+  width: 480
+  height: 640
+
+image_roi:
+  top_left: 
+    x: 60
+    y: 100
+  bottom_right:
+    x: 375
+    y: 380
+
 nn_compute: "cuda"
 nn_output_size:
   width: 120
@@ -11,9 +23,9 @@ gaussian_kernel:
   width: 0
   height: 0
 
-publish_markers: false
+publish_markers: true
 n_markers: 10
-m_markers: 15
+m_markers: 14
 
 depth_thresh:
   type: "exponential"
diff --git a/launch/gelsight_proc.launch b/launch/gelsight_proc.launch
index 669f3d8..3c21a3a 100644
--- a/launch/gelsight_proc.launch
+++ b/launch/gelsight_proc.launch
@@ -1,13 +1,10 @@
 <launch>
-  <arg name="use_http" default="true" />
 
   <node if="$(arg use_http)" name="republish" type="republish" pkg="image_transport" args="compressed in:=image/rectified raw out:=repub/rectified" />
 
   <node name="gelsight_proc" type="gelsight_proc.py" pkg="gelsight_ros" output="screen">
     <rosparam command="load" file="$(find gelsight_ros)/config/gelsight.yml"/>
     <rosparam command="load" file="$(find gelsight_ros)/config/gelsight_proc.yml"/>
-
-    <param name="use_http" value="$(arg use_http)"/>
     <param name="nn_path" value="$(find gelsight_ros)/data/nnr15.pt"/>
   </node>
 </launch>
diff --git a/scripts/gelsight_proc.py b/scripts/gelsight_proc.py
index d456051..1c4d3ac 100755
--- a/scripts/gelsight_proc.py
+++ b/scripts/gelsight_proc.py
@@ -17,10 +17,12 @@ from cv_bridge import CvBridge
 from gelsight_ros.msg import MarkerFlow
 
 from gelsight import gsdevice
-from gelsight import gs3drecon
+#from gelsight import gs3drecon
 
 from gelsight_ros.util import *
 
+from find_marker import Matching
+
 
 class ThreshType(Enum):
     GAUSSIAN = 1
@@ -42,11 +44,7 @@ if __name__ == "__main__":
     frame_id = rospy.get_param("~frame_id", "map")
     rate = rospy.Rate(rospy.get_param("~rate", 30))
 
-    use_http = rospy.get_param("~use_http", True)
-    cam_url = rospy.get_param("~cam_url", "")
-    if use_http and cam_url == "":
-        rospy.logfatal('No "cam_url" provided when "use_http" is true')
-
+    cam_url = rospy.get_param("~cam_url")
     width = rospy.get_param("~image_size/width")
     height = rospy.get_param("~image_size/height")
     roi = (
@@ -67,40 +65,48 @@ if __name__ == "__main__":
         else:
             rospy.logfatal(f"Depth thresh type not recognized: {depth_thresh_type}")
 
+
+    publish_markers = rospy.get_param("~publish_markers", False)
+    block_size = rospy.get_param("~flow/block_size", 41)
+    marker_top_left = rospy.get_param("~flow/top_left_corner", [10,10])
+    marker_spacing = rospy.get_param("~flow/marker_spacing", [10,10])
+    marker_n = rospy.get_param("~flow/n_markers")
+    marker_m = rospy.get_param("~flow/m_markers")
+    marker_fps = rospy.get_param("~flow/fps")
+    publish_depth = rospy.get_param("~publish_depth", False)
+
     nn_path = rospy.get_param("~nn_path")
     nn_compute = rospy.get_param("~nn_compute", "gpu")
     nn_output_width = rospy.get_param("~nn_output_size/width")
     nn_output_length = rospy.get_param("~nn_output_size/height")
     nn_mmpp = rospy.get_param("~nn_mmpp")
 
-    publish_markers = rospy.get_param("~publish_markers", False)
-    n_markers = rospy.get_param("~n_markers")
-    m_markers = rospy.get_param("~m_markers")
-
     gaussian_width = rospy.get_param("~gaussian_kernel/width")
     gaussian_height = rospy.get_param("~gaussian_kernel/height")
 
     pcl_pub = rospy.Publisher("/pcl", PointCloud2, queue_size=1)
-    contact_pub = rospy.Publisher("/contact", PoseStamped)
-    grasp_pub = rospy.Publisher("/grasped", Float32)
-    marker_flow_pub = rospy.Publisher("/flow", MarkerFlow)
-
-    if not use_http:
-        image_sub = rospy.Subscriber("/image/raw", Image, image_cb, queue_size=1)
-    else:
-        dev = gsdevice.Camera(gsdevice.Finger.R15, cam_url)
-        dev.connect()
-
-    nn = gs3drecon.Reconstruction3D(gs3drecon.Finger.R15)
-    nn.load_nn(nn_path, nn_compute)
-
-    init_frame = None
-    init_markers = None
-    init_dm = None
-    pca_buffer = deque([], maxlen=rospy.get_param("~pca_buffer_size"))
+    contact_pub = rospy.Publisher("/contact", PoseStamped, queue_size=10)
+    grasp_pub = rospy.Publisher("/grasped", Float32, queue_size=10)
+    marker_flow_pub = rospy.Publisher("/flow", MarkerFlow,queue_size=10)
+    marker_flow_img_pub = rospy.Publisher("/flow_img", Image,queue_size=10)
+
+    dev = gsdevice.Camera(gsdevice.Finger.R15, cam_url)
+    dev.connect()
+
+    if publish_markers:
+        init_frame = None
+        init_markers = None
+        match = Matching(marker_m, marker_n, marker_fps, *marker_top_left, *marker_spacing)
+        init_dm = None
+
+    if publish_depth:
+        nn = gs3drecon.Reconstruction3D(gs3drecon.Finger.R15)
+        nn.load_nn(nn_path, nn_compute)
+        pca_buffer = deque([], maxlen=rospy.get_param("~pca_buffer_size"))
+
     while not rospy.is_shutdown():
         try:
-            if use_http and dev.while_condition:
+            if dev.while_condition:
                 last_frame = dev.get_image(roi)
 
             if last_frame is not None:
@@ -110,46 +116,53 @@ if __name__ == "__main__":
                     init_frame = frame
 
                 if publish_markers:
-                    markers = image2markers(frame)
-                    flow_msg = markers2flow(markers, n_markers, m_markers, (12, 5), (11, 11))
-                    marker_flow_pub.publish(flow_msg)
-
-                dm = nn.get_depthmap(frame, False)
-
-                dm *= -1
-                if init_dm is None:
-                    init_dm = dm
-
-                dm = dm - init_dm
-
-                pcl = depth2pcl(nn_output_width, nn_output_length, nn_mmpp, dm)
-                pcl.header.frame_id = frame_id
-                pcl_pub.publish(pcl)
-
-                if depth_thresh_type is not None:
-                    if depth_thresh_type == ThreshType.GAUSSIAN:
-                        gauss = get_2d_gaussian(
-                            dm.shape[0], dm.shape[1], gauss_params["sig"]
-                        )
-                        thresh = dm - gauss
-                        dm[thresh > gauss_params["max"]] = 0.0
-                        dm[thresh < gauss_params["min"]] = 0.0
-                    elif depth_thresh_type == ThreshType.EXPONENTIAL:
-                        exp = get_2d_exponential(
-                            dm.shape[0], dm.shape[1], exp_params["beta"]
-                        )
-                        thresh = dm - exp
-                        dm[thresh > exp_params["max"]] = 0.0
-                        dm[thresh < exp_params["min"]] = 0.0
-
-                pose = depth2pca(dm, nn_mmpp, pca_buffer)
-                if pose is not None:
-                    pose.header.frame_id = frame_id
-                    contact_pub.publish(pose)
-
-                    grasp_pub.publish(Float32(1.0))
-                else:
-                    grasp_pub.publish(Float32(0.0))
+                    markers = image2markers(frame,block_size)
+                    flow = markers2flow(markers,match,marker_m,marker_n)
+                    if flow.vectors.mean() < 0: # ERROR 
+                        match = Matching(marker_m, marker_n, marker_fps, *marker_top_left, *marker_spacing)
+                    else:
+                        flow_msg = flow2msg(flow)
+                        marker_flow_pub.publish(flow_msg)
+                        flow_img = flow2image(flow,frame)
+                        marker_flow_img_pub.publish(bridge.cv2_to_imgmsg(flow_img,encoding='rgb8'))
+
+                if publish_depth:
+                    dm = nn.get_depthmap(frame, False)
+
+                    dm *= -1
+                    if init_dm is None:
+                        init_dm = dm
+
+                    dm = dm - init_dm
+
+                    pcl = depth2pcl(nn_output_width, nn_output_length, nn_mmpp, dm)
+                    pcl.header.frame_id = frame_id
+                    pcl_pub.publish(pcl)
+
+                    if depth_thresh_type is not None:
+                        if depth_thresh_type == ThreshType.GAUSSIAN:
+                            gauss = get_2d_gaussian(
+                                dm.shape[0], dm.shape[1], gauss_params["sig"]
+                            )
+                            thresh = dm - gauss
+                            dm[thresh > gauss_params["max"]] = 0.0
+                            dm[thresh < gauss_params["min"]] = 0.0
+                        elif depth_thresh_type == ThreshType.EXPONENTIAL:
+                            exp = get_2d_exponential(
+                                dm.shape[0], dm.shape[1], exp_params["beta"]
+                            )
+                            thresh = dm - exp
+                            dm[thresh > exp_params["max"]] = 0.0
+                            dm[thresh < exp_params["min"]] = 0.0
+
+                    pose = depth2pca(dm, nn_mmpp, pca_buffer)
+                    if pose is not None:
+                        pose.header.frame_id = frame_id
+                        contact_pub.publish(pose)
+
+                        grasp_pub.publish(Float32(1.0))
+                    else:
+                        grasp_pub.publish(Float32(0.0))
 
             rate.sleep()
         except rospy.ROSInterruptException:
diff --git a/scripts/vis_flow.py b/scripts/vis_flow.py
index 652dbd7..c174e49 100644
--- a/scripts/vis_flow.py
+++ b/scripts/vis_flow.py
@@ -7,14 +7,14 @@ from gelsight_ros.util import image2markers
 from find_marker import Matching
 
 URL = "http://192.168.0.170:8080/?action=stream"
-ROI = (70, 100, 335, 390)
+ROI = (70, 95, 335, 390)
 N = 10
 M = 14
 FPS = 40
-x0 = 13
-y0 = 5
-dx = 10
-dy = 10
+x0 = 10
+y0 = 11
+dx = 12
+dy = 12
 
 if __name__ == "__main__":
     dev = gsdevice.Camera(gsdevice.Finger.R15, URL)
@@ -54,4 +54,4 @@ if __name__ == "__main__":
 
             cv2.imshow("Flow Visualization", frame)
             if cv2.waitKey(1) != -1:
-                break
\ No newline at end of file
+                break
diff --git a/src/gelsight_ros/util.py b/src/gelsight_ros/util.py
index f588279..2d58786 100644
--- a/src/gelsight_ros/util.py
+++ b/src/gelsight_ros/util.py
@@ -1,10 +1,13 @@
 #!/usr/bin/env python3
 
+from dataclasses import dataclass
 import cv2
 from scipy.signal import fftconvolve
 from scipy import ndimage
 from scipy.ndimage.filters import maximum_filter, minimum_filter
 from math import sqrt
+import ros_numpy
+from typing import List
 import numpy as np
 from sensor_msgs.msg import Image, PointCloud2, PointField
 from gelsight_ros.msg import MarkerFlow
@@ -13,22 +16,33 @@ from std_msgs.msg import Header, Float32
 from geometry_msgs.msg import PoseStamped
 from tf.transformations import quaternion_from_euler
 from sensor_msgs import point_cloud2
-from numpy import linalg as LA
+from numpy import linalg as LA, ndarray
 import math
 from find_marker import Matching
 
+@dataclass
+class Flow:
+    Ox: List[List[float]]
+    Oy: List[List[float]]
+    Cx: List[List[float]]
+    Cy: List[List[float]]
+    markers: ndarray 
+    vectors: ndarray
+    n: int 
+    m: int 
+
 MARKER_INTENSITY_SCALE = 3
 MARKER_THRESHOLD = 255
 MARKER_TEMPLATE_SIZE = 5
 MARKER_TEMPLATE_RADIUS = 3
 MARKER_NEIGHBORHOOD_SIZE = 20
-MATCHING_FPS = 10
+MATCHING_FPS = 40
 MATCHING_SCALE = 5
 
-def image2markers(image):
+def image2markers(image, block_size = 41):
     # Mask markers
     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
-    mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 17, 25)
+    mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, block_size, 25)
 
     # # Gelsight Example Approach 
     # scaled = cv2.convertScaleAbs(gray, alpha=MARKER_INTENSITY_SCALE, beta=0)
@@ -70,25 +84,55 @@ def image2markers(image):
     return xy
 
 
-def markers2flow(markers, n, m, p0, dp):
-    match = Matching(m, n, MATCHING_FPS, p0[0], p0[1], dp[0], dp[1])
-
+def markers2flow(markers : ndarray,match : Matching,m : int,n : int):
     match.init(markers)
     match.run()
-
     Ox, Oy, Cx, Cy, _ = match.get_flow()
 
-    flow_msg = MarkerFlow()
-    flow_msg.n = n
-    flow_msg.m = m
+    vectors = np.zeros((m,n,3))
+
     for i in range(len(Ox)):
         for j in range(len(Ox[i])):
             x = MATCHING_SCALE * (Cx[i][j] - Ox[i][j])
             y = MATCHING_SCALE * (Cy[i][j] - Ox[i][j])
-            flow_msg.data.append(Vector3(x=x, y=y))
+            vectors[i,j,0] = x
+            vectors[i,j,1] = y
+            vectors[i,j,2] = 0
+
+    return Flow(Ox,Oy,Cx,Cy,markers,vectors, n,m) 
 
+def flow2msg(flow : Flow):
+    flow_msg = MarkerFlow()
+    flow_msg.n = flow.n
+    flow_msg.m = flow.m
+    vecs = np.reshape(flow.vectors,(flow.m * flow.n,3))
+    vecs = [ros_numpy.msgify(Vector3,vecs[i]) for i in range(len(vecs))]
+    flow_msg.data = vecs
     return flow_msg
 
+def flow2image(flow : Flow, frame):
+    K = 5
+    for i in range(len(flow.Ox)):
+        for j in range(len(flow.Ox[i])):
+            pt1 = (int(flow.Ox[i][j]), int(flow.Oy[i][j]))
+            pt2 = (int(flow.Cx[i][j] + K * (flow.Cx[i][j] - flow.Ox[i][j])), int(flow.Cy[i][j] + K * (flow.Cy[i][j] - flow.Oy[i][j])))
+            color = (0, 255, 255)
+            cv2.arrowedLine(frame, pt1, pt2, color, 2,  tipLength=0.2)
+    
+    for i in range(flow.markers.shape[0]):
+        cv2.circle(frame, (int(flow.markers[i, 0]), int(flow.markers[i, 1])), color=(0, 0, 0), radius=2)
+    return frame
+
+def curl_from_flow(flow : Flow):
+    def flow_at_point(flow : ndarray, pt):
+        x,y = pt
+        return flow[:flow.m,:y,0].sum() + \
+               flow[x:flow.m,:flow.n,1].sum() + \
+               flow[:flow.m,y:flow.n,0].sum() + \
+               flow[:x,:flow.n,1].sum()
+    vec_flow_at_point = np.vectorize(flow_at_point)
+    vec_flow_at_point(flow,np.arange(flow.m))
+    
 
 def depth2pcl(width, length, mmpp, dm):
     points = []
